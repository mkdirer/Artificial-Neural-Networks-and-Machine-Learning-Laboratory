{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ftn6Ty15G-Ir",
        "j6qWR3wzHE-z",
        "Zk-uPL0pRCIT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratorium 5 - Graph Neural Network"
      ],
      "metadata": {
        "id": "Ftn6Ty15G-Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "id": "tWwiwa8MHj7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ważne elementy konstruowania klasy GCN w PyTorch Geometrics:\n",
        "\n",
        "* **class GCN(torch.nn.Module):** definiuje klasę GCN dziedziczącą po klasie torch.nn.Module.**\n",
        "* **def __init__(self, hidden_channels):**definiuje konstruktor dla klasy GCN. Konstruktor ten przyjmuje jeden argument hidden_channels, który określa liczbę kanałów ukrytych.\n",
        "* **super(GCN, self).__init__():** wywołuje konstruktor klasy nadrzędnej, czyli torch.nn.Module.\n",
        "* **torch.manual_seed(12345)** ustawia seed dla generatora liczb losowych w PyTorch, co zapewnia, że wyniki będą deterministyczne i powtarzalne przy każdym uruchomieniu programu.\n",
        "* **self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)** definiuje pierwszą warstwę konwolucyjną, gdzie dataset.num_node_features określa liczbę cech wejściowych, a hidden_channels określa liczbę kanałów ukrytych.\n",
        "* **self.lin = Linear(hidden_channels, dataset.num_classes)** definiuje warstwę liniową klasyfikatora, gdzie hidden_channels to liczba wejściowych kanałów, a dataset.num_classes to liczba klas, które chcemy przewidzieć.\n"
      ],
      "metadata": {
        "id": "u9sgtS7J_gp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Podstawy GNN (Karate Club)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j6qWR3wzHE-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zapoznaj się z dokumentacja PyTorch Geometrics. Dokonaj modyfikacji w budowaniu architektury sieci GNN oraz procesu jej uczenia (Optymalizatory, funkcje aktywacji, funkcje straty).\n",
        "\n",
        "Czym są elementy pętli uczącej :\n",
        "* optimizer.zero_grad()\n",
        "* loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "* loss.backward()\n",
        "* optimizer.step()\n",
        "* model.eval()\n",
        "\n",
        "Zaproponuj dodanie Early Stoppingu do tego modelu (działanie takie samo jak w Kerasie ale trzeba zaimplementować to ręcznie) . Podziel kod na odseparowane komórki żeby wyglądał bardziej składnie i czytelnie."
      ],
      "metadata": {
        "id": "vHhjWBTUq99J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja do rysowania grafu oryginalnego\n",
        "import networkx as nx\n",
        "\n",
        "def draw_true_graph(G):\n",
        "    pos = nx.spring_layout(G, seed=42)\n",
        "    colors = ['#1f78b4' if data.y[i] == 0 else '#33a02c' for i in range(G.number_of_nodes())]\n",
        "    plt.subplot(1, 2, 1)\n",
        "    nx.draw(G, pos=pos, with_labels=True, node_color=colors, edgecolors='gray')\n",
        "    plt.title('True Labels')\n",
        "\n",
        "# Wyświetl predykcje\n",
        "def draw_graph_predict(G, pred):\n",
        "    pos = nx.spring_layout(G, seed=42)\n",
        "    colors = ['#1f78b4' if p == 0 else '#33a02c' for p in pred]\n",
        "    plt.subplot(1, 2, 2)\n",
        "    nx.draw(G, pos=pos, with_labels=True, node_color=colors, edgecolors='gray')\n",
        "    plt.title('Predicted Labels')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "B94CE3ggN1u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import KarateClub\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "# Załaduj zbiór danych Karate Club\n",
        "dataset = KarateClub()\n",
        "\n",
        "# Wczytaj pierwszy graf z zestawu danych\n",
        "data = dataset[0]\n",
        "\n",
        "# Wyznacz losowo 10 węzłów uczących się\n",
        "import random\n",
        "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "data.train_mask[random.sample(range(data.num_nodes), 10)] = 1\n",
        "\n",
        "# Zdefiniuj model GNN\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = GCNConv(dataset.num_features, 16)\n",
        "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)  # pierwsza warstwa konwolucyjna na wejściu x i krawędziach edge_index\n",
        "        x = F.relu(x)  # nieliniowa funkcja aktywacji - ReLU\n",
        "        x = F.dropout(x, training=self.training)  # regularyzacja - dropout\n",
        "        x = self.conv2(x, edge_index)  # druga warstwa konwolucyjna na wyjściu z poprzedniej warstwy i krawędziach edge_index\n",
        "        return F.log_softmax(x, dim=1)  # funkcja softmax zwracająca prawdopodobieństwa przynależności do klas, zwracana wartość jest zlogarytmowana (log_softmax)\n",
        "\n",
        "\n",
        "# Zainicjuj model i funkcję kosztu\n",
        "model = Net()\n",
        "criterion = torch.nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "# Konwertuj dane na graf\n",
        "G = to_networkx(data)\n",
        "\n",
        "from torch_geometric.utils.convert import to_networkx\n",
        "\n",
        "# Pętla ucząca z wyświetlaniem klasyfikacji za każdą epoką\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    model.eval()\n",
        "    pred = model(data.x, data.edge_index).argmax(dim=1)\n",
        "    acc = (pred[data.train_mask] == data.y[data.train_mask]).float().mean()\n",
        "    print(f'Epoch {epoch}: Train Accuracy: {acc:.4f}')\n",
        "    \n",
        "    draw_true_graph(to_networkx(data))\n",
        "    draw_graph_predict(to_networkx(data), pred)\n",
        "\n",
        "\n",
        "# Ustaw model w tryb ewaluacji i wyświetl wyniki\n",
        "model.eval()\n",
        "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
        "acc = (pred[data.train_mask] == data.y[data.train_mask]).float().mean()\n",
        "print(f'Final Training Accuracy: {acc:.4f}')\n",
        "\n",
        "# Wyświetl wyniki klasyfikacji dla wszystkich węzłów\n",
        "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
        "print(f'Predicted Class Labels: {pred}')\n"
      ],
      "metadata": {
        "id": "HaKNH5HqJWjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Texas Dataset (WebKG)"
      ],
      "metadata": {
        "id": "C_8JxEI-doP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dokonaj podobnych modyfikacji jak w datasecie Karate Club. Coś się zmieniło? Jak to wpływa na finalny wynik?"
      ],
      "metadata": {
        "id": "PUYc4gl-8CZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "def draw_true_graph_texas(G):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    pos = nx.spring_layout(G, seed=42)\n",
        "    nx.draw_networkx_nodes(G, pos, node_color=data.y, cmap='Set1', node_size=500)\n",
        "    nx.draw_networkx_edges(G, pos)\n",
        "    plt.title(\"True Graph\")\n",
        "    plt.show()\n",
        "\n",
        "def draw_graph_predict_texas(G, pred):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    pos = nx.spring_layout(G, seed=42)\n",
        "    nx.draw_networkx_nodes(G, pos, node_color=pred, cmap='Set1', node_size=500)\n",
        "    nx.draw_networkx_edges(G, pos)\n",
        "    plt.title(\"Predicted Graph\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "zPEbjl7ueb31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import WebKB\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "# Load the WebKB dataset\n",
        "dataset = WebKB(root='.', name='texas')\n",
        "\n",
        "# Load the first graph from the dataset\n",
        "data = dataset[0]\n",
        "\n",
        "# Randomly select 10 nodes as training nodes\n",
        "import random\n",
        "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "data.train_mask[random.sample(range(data.num_nodes), 10)] = 1\n",
        "\n",
        "# Define the GNN model\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
        "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Initialize the model and loss function\n",
        "model = Net()\n",
        "criterion = torch.nn.NLLLoss()\n",
        "\n",
        "# Define the optimizer and train for 200 epochs\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "# Convert the data to a networkx graph\n",
        "G = to_networkx(data)\n",
        "\n",
        "# Training loop with classification output for each epoch\n",
        "for epoch in range(30):\n",
        "    print(f\"---------------------------- EPOCH: {epoch}---------------------------------------\")\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    model.eval()\n",
        "    pred = model(data.x, data.edge_index).argmax(dim=1)\n",
        "    acc = (pred[data.train_mask] == data.y[data.train_mask]).float().mean()\n",
        "    print(f'Epoch {epoch}: Train Accuracy: {acc:.4f}')\n",
        "\n",
        "    # Draw the true graph and the predicted graph\n",
        "    draw_true_graph_texas(to_networkx(data))\n",
        "    draw_graph_predict_texas(to_networkx(data), pred)\n",
        "\n",
        "    print(\"-------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "# Set the model to evaluation mode and display the results\n",
        "model.eval()\n",
        "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
        "acc = (pred[data.train_mask] == data.y[data.train_mask]).float().mean()\n",
        "print(f'Final Training Accuracy: {acc:.4f}')\n",
        "\n",
        "# Display the classification results for all nodes\n",
        "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
        "print(f'Predicted Class Labels: {pred}')\n"
      ],
      "metadata": {
        "id": "T66pcVQDdoDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. [Cora Dataset](https://graphsandnetworks.com/the-cora-dataset/)\n",
        "Bardzo brzydko rysuje grafy i trwa dość długo - ale jak ktoś ma ochote poznac bardziej bibliotekę PyTorch Geometrics i GNN to polecam zainteresować się datasetami Cora, PubMed oraz CiteSeer  (dostępne z poziomu biblioteki PyTorch Geometrics)"
      ],
      "metadata": {
        "id": "Zk-uPL0pRCIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "def draw_true_graph_cora(G):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    pos = nx.spring_layout(G, seed=42)\n",
        "    nx.draw_networkx_nodes(G, pos, node_color=data.y, cmap='Set1', node_size=500)\n",
        "    nx.draw_networkx_edges(G, pos)\n",
        "    plt.title(\"True Graph\")\n",
        "    plt.show()\n",
        "\n",
        "def draw_graph_predict_cora(G, pred):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    pos = nx.spring_layout(G, seed=42)\n",
        "    nx.draw_networkx_nodes(G, pos, node_color=pred, cmap='Set1', node_size=500)\n",
        "    nx.draw_networkx_edges(G, pos)\n",
        "    plt.title(\"Predicted Graph\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "4IVjCREufZZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import DataLoader\n",
        "import random\n",
        "\n",
        "\n",
        "from torch_geometric.datasets import Planetoid\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "data = dataset[0]\n",
        "\n",
        "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "data.train_mask[random.sample(range(data.num_nodes), 100)] = 1\n",
        "\n",
        "\n",
        "# Zdefiniuj model GNN\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = GCNConv(dataset.num_features, 64)\n",
        "        self.conv2 = GCNConv(64, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Zainicjuj model i funkcję kosztu\n",
        "model = Net()\n",
        "criterion = torch.nn.NLLLoss()\n",
        "\n",
        "# Zdefiniuj optymalizator i uczenie przez 200 epok\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "# Konwertuj dane na graf\n",
        "G = to_networkx(data)\n",
        "\n",
        "from torch_geometric.utils.convert import to_networkx\n",
        "\n",
        "# Pętla ucząca z wyświetlaniem klasyfikacji za każdą epoką\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    model.eval()\n",
        "    pred = model(data.x, data.edge_index).argmax(dim=1)\n",
        "    acc = (pred[data.train_mask] == data.y[data.train_mask]).float().mean()\n",
        "    print(f'Epoch {epoch}: Train Accuracy: {acc:.4f}')\n",
        "    \n",
        "    draw_true_graph_cora(to_networkx(data))\n",
        "    draw_graph_predict_cora(to_networkx(data), pred)\n",
        "\n",
        "\n",
        "# Ustaw model w tryb ewaluacji i wyświetl wyniki\n",
        "model.eval()\n",
        "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
        "acc = (pred[data.train_mask] == data.y[data.train_mask]).float().mean()\n",
        "print(f'Final Training Accuracy: {acc:.4f}')\n",
        "\n",
        "# Wyświetl wyniki klasyfikacji dla wszystkich węzłów\n",
        "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
        "print(f'Predicted Class Labels: {pred}')"
      ],
      "metadata": {
        "id": "S62FjtOKSjaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Klasyfikacja grafów (nie węzłów) z datasetem MUTAG\n",
        "\n",
        "Bardzo brzydko rysuje grafy ale nie trwa jakoś długo. Do wizualizacji grafów w sieciach GNN używa sie zewnętrznych narzędzi które to ułatwiają - tutaj niestety NetworkX jest niewystarczające.\n",
        "\n",
        "Twoim zdaniem będzie sprawdzić wpływ większej ilości warstw GCN w modelu. Spróbuj dodać/usunąć warstwe."
      ],
      "metadata": {
        "id": "J1BQop5ptWdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "def visualize_graph_classification(graph, true_label, predicted_label):\n",
        "    G = nx.Graph()\n",
        "    G.add_nodes_from(range(graph.num_nodes))\n",
        "    G.add_edges_from(graph.edge_index.t().tolist())\n",
        "\n",
        "    node_colors = []\n",
        "    if len(true_label) == graph.num_nodes:\n",
        "        for i in range(graph.num_nodes):\n",
        "            if true_label[i] == 1:\n",
        "                node_colors.append('red')\n",
        "            else:\n",
        "                node_colors.append('blue')\n",
        "    else:\n",
        "        node_colors = ['blue'] * graph.num_nodes\n",
        "\n",
        "    pos = nx.spring_layout(G)\n",
        "    nx.draw(G, pos, with_labels=True, node_color=node_colors)\n",
        "    plt.title(f\"Predicted label: {predicted_label}\")\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "8apd35dbzeeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import biblioteki PyTorch oraz klasy TUDataset z biblioteki torch_geometric.datasets\n",
        "import torch\n",
        "from torch_geometric.datasets import TUDataset\n",
        "\n",
        "# Pobierz zbiór danych MUTAG z bazy TUDataset\n",
        "dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
        "\n",
        "# Wyświetl informacje o zbiorze danych MUTAG\n",
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('====================')\n",
        "print(f'Number of graphs: {len(dataset)}') # Liczba grafów w zbiorze danych\n",
        "print(f'Number of features: {dataset.num_features}') # Liczba cech w każdym grafie\n",
        "print(f'Number of classes: {dataset.num_classes}') # Liczba klas, na które można podzielić grafy\n",
        "\n",
        "# Pobierz pierwszy graf z dataset\n",
        "data = dataset[0]\n",
        "\n",
        "# Wyświetl informacje o pierwszym grafie\n",
        "print()\n",
        "print(data) # Wyświetl informacje o pierwszym grafie\n",
        "print('=============================================================')\n",
        "\n",
        "# Oblicz niektóre statystyki dla pierwszego grafu\n",
        "print(f'Number of nodes: {data.num_nodes}') # Liczba węzłów w grafie\n",
        "print(f'Number of edges: {data.num_edges}') # Liczba krawędzi w grafie\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}') # Średni stopień węzła\n",
        "print(f'Has isolated nodes: {data.has_isolated_nodes()}') # Czy graf zawiera izolowane węzły?\n",
        "print(f'Has self-loops: {data.has_self_loops()}') # Czy graf zawiera pętle?\n",
        "print(f'Is undirected: {data.is_undirected()}') # Czy graf jest nieskierowany?\n",
        "\n",
        "# Ustaw ziarno losowości dla biblioteki PyTorch\n",
        "torch.manual_seed(12345)\n",
        "\n",
        "# Przetasuj zbiór danych MUTAG\n",
        "dataset = dataset.shuffle()\n",
        "\n",
        "# Podziel zbiór danych na zbiór treningowy i testowy\n",
        "train_dataset = dataset[:150]\n",
        "test_dataset = dataset[150:]\n",
        "\n",
        "# Wyświetl informacje o podziale zbioru danych\n",
        "print(f'Number of training graphs: {len(train_dataset)}') # Liczba grafów w zbiorze treningowym\n",
        "print(f'Number of test graphs: {len(test_dataset)}') # Liczba grafów w zbiorze testowym\n",
        "\n",
        "# Załaduj dane z podzielonego zbioru danych do DataLoader\n",
        "from torch_geometric.loader import DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) # DataLoader dla zbioru treningowego\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False) # DataLoader dla zbioru testowego\n",
        "\n",
        "# Zdefiniuj model GCN\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)  # pierwsza warstwa konwolucyjna\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)  # druga warstwa konwolucyjna\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)  # trzecia warstwa konwolucyjna\n",
        "        self.lin = Linear(hidden_channels, dataset.num_classes)  # warstwa liniowa klasyfikatora\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # 1. Obliczenie osadzeń węzłów\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        # 2. Warstwa agregacji\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "        # 3. Zastosowanie klasyfikatora\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = GCN(hidden_channels=64)  # Tworzenie obiektu reprezentującego GCN o rozmiarze warstwy ukrytej 64\n",
        "print(model)\n",
        "\n",
        "\n",
        "model = GCN(hidden_channels=64)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Definicja optymalizatora Adam\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Definicja funkcji kosztu CrossEntropyLoss\n",
        "\n",
        "def train():\n",
        "    model.train()  # Ustawienie modelu w trybie treningowym\n",
        "\n",
        "    for data in train_loader:  # Iteracja po danych treningowych w paczkach\n",
        "         out = model(data.x, data.edge_index, data.batch)  # Wykonanie jednego przejścia sieci\n",
        "         loss = criterion(out, data.y)  # Obliczenie funkcji kosztu\n",
        "         loss.backward()  # Obliczenie gradientów\n",
        "         optimizer.step()  # Aktualizacja parametrów na podstawie gradientów\n",
        "         optimizer.zero_grad()  # Wyczyszczenie gradientów\n",
        "\n",
        "def test(loader):\n",
        "     model.eval()  # Ustawienie modelu w trybie testowym\n",
        "\n",
        "     correct = 0\n",
        "     for data in loader:  # Iteracja po danych testowych w paczkach\n",
        "         out = model(data.x, data.edge_index, data.batch)  \n",
        "         pred = out.argmax(dim=1)  # Użycie klasy z najwyższym prawdopodobieństwem\n",
        "         correct += int((pred == data.y).sum())  # Sprawdzenie z etykietami prawdziwymi\n",
        "     return correct / len(loader.dataset)  # Obliczenie wskaźnika poprawności predykcji\n",
        "\n",
        "\n",
        "for epoch in range(1, 171):\n",
        "    print(f\"------------------------------ START {epoch}------------------------------\")\n",
        "    train()\n",
        "    train_acc = test(train_loader)\n",
        "    test_acc = test(test_loader)\n",
        "    \n",
        "    # Add visualization code here\n",
        "    for data in train_loader:\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        pred = out.argmax(dim=1)\n",
        "        visualize_graph_classification(data, data.y.tolist(), pred.tolist())\n",
        "\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "    print(f\"------------------------------ END {epoch}------------------------------\")\n"
      ],
      "metadata": {
        "id": "Y2jCrV1OxVzJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}