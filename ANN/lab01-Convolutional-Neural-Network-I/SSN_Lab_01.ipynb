{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYRqVmBnmJ80"
      },
      "source": [
        "# Laboratorium 1 - Convolutional Neural Network cz. I\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k75-jR1bdM3g"
      },
      "source": [
        "Celem pierwszych zajęć jest instalacja bibliotek używanych na zajęciach oraz wprowadzenie do języka Python. Zajęcia będą przedstawiane w formacie notatników Jupyter. Każda osoba ma możliwość używania dowolnych narzędzi i systemu operacyjnego z którymi czuje się komfortowo. \n",
        "\n",
        "Rekomendowane biblioteki:\n",
        "\n",
        "*   [PyTorch](https://pytorch.org/docs/stable/index.html)\n",
        "*   [Keras](https://keras.io/api/)\n",
        "*   [PyTorch Geometrics](https://pytorch-geometric.readthedocs.io/en/latest/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzI_LWY5dNEw"
      },
      "source": [
        "# *Zadanie 1*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynI2VRK-mCH8"
      },
      "source": [
        "Po zapoznaniu się z obsluga interfejsu Google Colab. **Zaimplementuj** trzy wielowarstwowe Convolutional Neural Networks (CNNs) do klasyfikacji datasetów:\n",
        "* [MNIST](https://paperswithcode.com/dataset/mnist)\n",
        "* [Fashion MNIST](https://paperswithcode.com/dataset/fashion-mnist)\n",
        "* [CIFAR-10](https://paperswithcode.com/dataset/cifar-10)\n",
        "\n",
        "W tym celu wykorzystaj biblioteke **Keras** albo **PyTorch**.\n",
        "\n",
        "Ponizej przyklad jak wczytac dane w **Keras**\n",
        "\n",
        "```\n",
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkohblYAk3ol"
      },
      "source": [
        "# *Wprowadzenie do CNN*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IFthapDk3x4"
      },
      "source": [
        "Pierwsza warstwa zawsze musi posiadać parametr input_shape, który mówi o tym jakie dane dostanie sieć neuronowa na początku. **Input Layer** Jest to warstwa wejściowa, która reprezentuje obraz wejściowy do sieci. Warto zwrócić uwagę na rodzaj obrazu, który mamy. W przypadku kolorowych zdjęć będziemy używać trzech kanałów wejściowych RGB, odpowiadającym odpowiednio kanałom czerwonym, zielonym i niebieskim. W naszym przypadku (Fashion Mnist) mamy skalę szarości i dlatego mamy jeden kanał.\n",
        "\n",
        "**Warstwa wejściowa (Input Layer)**\n",
        "Jest to warstwa wejściowa, która reprezentuje obraz wejściowy do sieci. Warto zwrócić uwagę na rodzaj obrazu, który mamy. W przypadku kolorowych zdjęć będziemy używać trzech kanałów wejściowych RGB, odpowiadającym odpowiednio kanałom czerwonym, zielonym i niebieskim. W naszym przypadku (Fashion Mnist) mamy skalę szarości i dlatego mamy jeden kanał.\n",
        "\n",
        "Warstwa wejsciowa jako Conv2D:\n",
        "```\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwDFwaQ_k3u3"
      },
      "source": [
        "**Warstwa konwolucyjna / splotowa (Convolutional Layers)**\n",
        "\n",
        "Warstwy splotowe są podstawą sieci konwolucyjnych CNN, ponieważ zawierają wyuczone filtry (kernele), które wyodrębniają cechy odróżniające od siebie różne obrazy.\n",
        "\n",
        "Kiedyś zastanawiałem się, dlaczego definiując warstwę CNN nie podajemy tych filtrów. Tak naprawdę wartości w filtrach (tak jak wyżej sami mogliście sobie dobrać, jakie chcieliście) są dobierane i optymalizowane podczas trenowania sieci. I są dobrane tak, by minimalizować błąd naszej sieci przy rozwiązywaniu problemu, który zdefiniujemy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKyNKYSyxs5R"
      },
      "source": [
        "**Kernel Size (rozmiar jądra)**\n",
        "Rozmiar jądra, często nazywany również rozmiarem filtra, odnosi się do wymiarów przesuwanego okna nad wejściem. Wybór tego hiperparametru ma ogromny wpływ na zadanie klasyfikacji obrazu. Na przykład małe jądra są w stanie wydobyć z danych wejściowych znacznie większą ilość informacji zawierających wysoce lokalne funkcje. Mniejszy rozmiar jądra prowadzi również do mniejszego zmniejszenia wymiarów warstw, co pozwala na głębszą architekturę.\n",
        "\n",
        "**Padding (wypełnienie)**\n",
        "Padding definiuje sposób obsługi obramowania próbki. Umożliwia to otrzymanie rozmiaru wyjścia takiego samego jak rozmiar wejścia (przy założeniu, że strides jest przesunięciem o jeden). Osiąga się to kosztem dodania dodatkowych (sztucznych) wag na krawędziach (najczęściej z wartością zero). Dlaczego z zerami? Bo są wydajne – zapewniają prostotę i wydajność obliczeniową. \n",
        "\n",
        "\n",
        "**Strides (kroki)**\n",
        "Parametr stride wskazuje, o ile pikseli jądro powinno zostać przesunięte na raz. Czyli inaczej mówiąc, oznacza krok przesunięcia okna filtra. Najczęściej używa się kroku wynoszącego 1 dla warstw splotowych. Oznacza to, że ​​iloczyn skalarny jest wykonywany w oknie wejściowym np. 3×3 w celu uzyskania wartości wyjściowej, a następnie jest przesuwany o jeden piksel dla każdej kolejnej operacji.\n",
        "\n",
        "```\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlyruisfyPG-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1qd_rn6k3rt"
      },
      "source": [
        "**Warstwa Flatten**\n",
        "\n",
        "Jest to ważny krok. Ta warstwa przekształca naszą wielowymiarową warstwę w sieci w jednowymiarowy wektor. Robimy to po to, aby dopasować dane wejściowe w pełni połączonej warstwy do klasyfikacji. Na przykład tensor o wielkości 10x10x3 zostałby przekształcony w wektor o rozmiarze 300 (1 x 300).\n",
        "\n",
        "Dlaczego to robimy? Bo zadaniem poprzedzających warstw splotowych sieci było wyodrębnienie cechy z obrazu wejściowego. A teraz nadszedł najwyższy czas, aby sklasyfikować cechy.\n",
        "\n",
        "Najczęściej używamy funkcji softmax do klasyfikowania tych cech, co wymaga jednowymiarowych danych wejściowych. Dlatego konieczna jest spłaszczona warstwa.\n",
        "\n",
        "```\n",
        "model.add(Flatten())\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbKHaGX7lKfQ"
      },
      "source": [
        "**Warstwa Dense**\n",
        "Warstwę gęstą (ang. dense layer lub fully connected layer), w której wszystkie neurony z warstwy wcześniejszej są połączone ze wszystkimi neuronami z warstwy kolejnej. Warstwy te (oraz ewentualnie inne, przystosowane do konkretnego zagadnienia) mogą występować w sieci wielokrotnie, na różnych poziomach, z różnymi konfiguracjami. Zaprojektowanie dobrej sieci neuronowej jest kluczowym czynnikiem decydującym o jej skuteczności i szybkości trenowania i działania."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIpgTCpXxJlz"
      },
      "source": [
        "**Warstwy poolingu**  to warstwy które wykorzystuje się w sieciach neuronowych do zmniejszania wymiarowości przestrzeni cech. W Keras dostępne są dwie podstawowe warstwy poolingu:\n",
        "\n",
        "1. MaxPooling2D - wykonuje operację poolingu z użyciem największej wartości na obszarze próbkowania. Ta warstwa jest powszechnie używana w sieciach konwolucyjnych i pomaga zmniejszyć rozmiar map cech.\n",
        "\n",
        "2. AveragePooling2D - wykonuje operację poolingu poprzez uśrednienie wartości na obszarze próbkowania. Ta warstwa jest również często stosowana w sieciach konwolucyjnych, szczególnie gdy chcemy zmniejszyć rozmiar map cech, ale nie chcemy tracić tak wiele informacji jak w przypadku warstwy MaxPooling2D.\n",
        "\n",
        "Obie warstwy poolingu mają parametry, takie jak rozmiar okna próbkowania i krok, które pozwalają na dostosowanie sposobu, w jaki jest przeprowadzane próbkowanie.\n",
        "\n",
        "Idea poolingu polega na tym, że kilka pikseli np. rozmiar 2×2 mapujemy na 1 piksel. Najbardziej znane są dwa rodzaje poolingów:\n",
        "\n",
        "* max (maximum) – gdy bierzemy maksymalną wartość z 4 pikseli,\n",
        "* avg (avarage) – gdy bierzemy średnią wartość z 4 pikseli.\n",
        "\n",
        "```\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGIGO5NUkhKe"
      },
      "source": [
        "**Funkcje aktywacji**\n",
        "\n",
        "O różnych funkcjach aktywacji przeczytaj -> [klikając tutaj](https://laptrinhx.com/complete-guide-of-activation-functions-574622854/)\n",
        "\n",
        "```\n",
        "model.add(Dense(10, activation = 'softmax'))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJcRW_RQkqhT"
      },
      "source": [
        "**Funkcje straty**\n",
        "\n",
        "* dla klasyfikacji binarnej użycie binarnej entropii krzyżowej (binary_crossentropy),\n",
        "* dla klasyfikacji wielowymiarowej użycie kategoryzującej entropii krzyżowej (categorical _crossentropy),\n",
        "* w przypadku regresji błąd średniokwadratowy (mse).\n",
        "\n",
        "\n",
        "``` \n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxC6MnYJnA7v"
      },
      "source": [
        "**Optymalizatory**\n",
        "\n",
        "Optymalizator — mechanizm dostrajania sieci na podstawie danych zwracanych przez funkcję straty. Strata jest wartością, którą sieć będzie próbowała minimalizować podczas trenowania,\n",
        "a więc powinna być miarą sukcesu w rozwiązaniu danego problemu.\n",
        "Optymalizator określa dokładnie sposób używania gradientu straty podczas aktualizacji parametrów: w sieci neuronowej możesz zastosować np. algorytm optymalizatora RMSProp czy algorytm stochastycznego spadku wzdłuż gradientu z pędem.\n",
        "\n",
        "Konfiguracja optymalizacji — z jakiego optymalizatora będziesz korzystać?\n",
        "Jaki współczynnik uczenia wybierzesz? W większości sytuacji bezpiecznym wyborem jest optymalizator rmsprop i domyślna wartość jego współczynnika uczenia. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YnIcIkQwLzg"
      },
      "source": [
        "1. Gradient Descent - jest to najprostszy optymalizator, który polega na iteracyjnej aktualizacji wag na podstawie wartości gradientu funkcji straty. Można wyróżnić kilka wariantów Gradient Descent, m.in. Batch Gradient Descent, Stochastic Gradient Descent oraz Mini-Batch Gradient Descent.\n",
        "\n",
        "2. Momentum - optymalizator ten dodaje do aktualizacji wag informacje o poprzedniej iteracji, co ma na celu przyspieszenie procesu uczenia oraz zapobieganie utknięciu w minimach lokalnych funkcji straty.\n",
        "\n",
        "3. Adagrad - optymalizator ten dostosowuje tempo uczenia dla każdej wagi na podstawie historycznych wartości gradientu. Wagi, które często się aktualizują, mają mniejsze tempo uczenia, a te, które są aktualizowane rzadziej, mają większe tempo uczenia.\n",
        "\n",
        "4. Adadelta - optymalizator ten jest podobny do Adagrad, ale zamiast wykorzystywać historyczne wartości gradientu, korzysta z historycznych wartości kwadratów aktualizacji wag. Ma to na celu przeciwdziałanie problemowi zanikającego lub eksplodującego gradientu.\n",
        "\n",
        "5. Adam - optymalizator ten łączy cechy Momentum i Adagrad. Wprowadza również nowe pojęcie estymacji momentów, które pozwala na adaptacyjną zmianę tempa uczenia w zależności od wartości gradientu oraz historycznych wartości.\n",
        "\n",
        "6. RMSProp - optymalizator ten polega na adaptacyjnym modyfikowaniu tempa uczenia dla każdej wagi, ale zamiast korzystać z historycznych wartości gradientu, korzysta z wykładniczo ważonych średnich kwadratów gradientu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvamC3JAwjMO"
      },
      "source": [
        "**Metryki** te są wykorzystywane do oceny jakości predykcji modelu podczas procesu treningu oraz testowania.\n",
        "\n",
        "\n",
        "1. Accuracy - metryka ta mierzy procent poprawnych klasyfikacji w zbiorze danych.\n",
        "\n",
        "2. Binary accuracy - metryka ta mierzy procent poprawnych klasyfikacji dla problemów binarnych.\n",
        "\n",
        "3. Categorical accuracy - metryka ta mierzy procent poprawnych klasyfikacji dla problemów wieloklasowych.\n",
        "\n",
        "4. Precision - metryka ta mierzy proporcję poprawnie sklasyfikowanych przykładów pozytywnych do ogólnej liczby sklasyfikowanych pozytywnie.\n",
        "\n",
        "5. Recall - metryka ta mierzy proporcję poprawnie sklasyfikowanych przykładów pozytywnych do ogólnej liczby prawdziwych pozytywnych.\n",
        "\n",
        "6. F1 score - metryka ta jest średnią harmoniczną precyzji i recall, a więc uwzględnia zarówno false positives, jak i false negatives.\n",
        "\n",
        "7. Mean squared error (MSE) - metryka ta mierzy średnią kwadratową różnicę między predykcjami a rzeczywistymi wartościami.\n",
        "\n",
        "8. Root mean squared error (RMSE) - metryka ta mierzy pierwiastek średniej kwadratowej różnicy między predykcjami a rzeczywistymi wartościami.\n",
        "\n",
        "9. Mean absolute error (MAE) - metryka ta mierzy średnią wartość bezwzględną różnicy między predykcjami a rzeczywistymi wartościami."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6DTMJy7nEbz"
      },
      "source": [
        "**Przykłady**\n",
        "\n",
        "* **Klasyfikacja binarna** Funkcja na ostatniej warstwie: **sigmoid** Funkcja straty: **binary_crossentropy**\n",
        "* **Wieloklasowa klasyfikacja jednoetykietowa** Funkcja na ostatniej warstwie:  **softmax** Funkcja straty: **categorical_crossentropy**\n",
        "* **Wieloklasowa klasyfikacja wieloetykietowa**  Funkcja na ostatniej warstwie: **sigmoid** Funkcja straty:**binary_crossentropy**\n",
        "* **Regresja dowolnych wartości** Funkcja na ostatniej warstwie:  **Brak**  Funkcja straty: **MSE**\n",
        "* **Regresja wartości z zakresu od 0 do 1** Funkcja na ostatniej warstwie:  **sigmoid** Funkcja straty: n**MSE** lub **binary_crossentropy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu5DBELTrWWL"
      },
      "source": [
        "**Overfitting** - najprosciej (widac to na wykresach Train vs Valid) oddalanie sie wartosci metryki (np. accuracy) w procesie uczenia a w procesie testu. Co w przypadku SSN oznacza tyle że sieć na tyle dobrze nauczyła się klasyfikować zbiór treningowy, że utraciła jednocześnie zdolność do generalizowania, czyli umiejętność poprawnej klasyfikacji danych, których uprzednio nie widziała."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-XTzlGFvYYk"
      },
      "source": [
        "**Batch normalization** to technika normalizacji danych wejściowych do sieci neuronowych, która ma na celu przyspieszenie procesu uczenia oraz poprawę jakości predykcji modelu.\n",
        "\n",
        "W skrócie, batch normalization polega na przeskalowaniu i przesunięciu wartości wejściowych każdej warstwy sieci neuronowej tak, aby średnia wartość była bliska 0 i wariancja bliska 1.\n",
        "\n",
        "W praktyce, podczas treningu sieci neuronowej, wartości wejściowe do każdej warstwy zmieniają się wraz z każdą iteracją i batch normalization normalizuje wartości wejściowe w obrębie jednej mini-batch, czyli małej podgrupy przykładów uczących, które są przetwarzane jednocześnie. Dzięki temu, model jest mniej wrażliwy na zmiany w rozkładzie danych wejściowych, a co za tym idzie, ma większą stabilność i efektywność w procesie uczenia.\n",
        "\n",
        "``` \n",
        "# Model with default batch normalization\n",
        "model = Sequential([\n",
        "    Dense(64, input_shape=(4,), activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(\n",
        "        momentum=0.95, \n",
        "        epsilon=0.005,\n",
        "        beta_initializer=RandomNormal(mean=0.0, stddev=0.05), \n",
        "        gamma_initializer=Constant(value=0.9)\n",
        "    ),\n",
        "    Dense(3, activation='softmax')\n",
        "]);\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lOfK0zclW4r"
      },
      "source": [
        "**Metoda porzucania (dropout)**\n",
        "*   Jest to najpopularniejszy sposób do walki z przetrenowaniem w przypadku sieci neuronowych. Dropout polega na losowym ustawieniu wychodzących krawędzi ukrytych jednostek (neuronów tworzących ukryte warstwy) na 0 przy każdej aktualizacji fazy treningu.\n",
        "\n",
        "*   W Tensorflow dodajemy kolejne warstwy wykorzystując „Dropout” oraz definiując jaka część neuronów ma zostać zapomniana. Np. dla wartości 0.2 zostanie wylosowanych 20% połączeń do wyzerowania.\n",
        "\n",
        "```\n",
        "from tensorflow.keras.layers import Dropout\n",
        "model.add(Dropout(0.2))\n",
        "```\n",
        "\t\n",
        "*   Można jeszcze warstwę dodać na samym początku podczas wczytywania danych. Dzięki temu będziemy „porzucać” część danych wejściowych.\n",
        "\n",
        "```\n",
        "model.add(Dropout(0.5, input_shape=(28,28)))\n",
        "```\n",
        "\n",
        "Jest to relatywnie prosta, ale zarazem bardzo skuteczna technika przeciwdziałania overfittingowi. Polega na losowym usuwaniu z sieci (z warstw wewnętrznych, czasami również wejściowych) pojedynczych neuronów w trakcie uczenia. Ponieważ skomplikowane sieci (a takie niewątpliwie są głębokie sieci neuronowe), szczególnie dysponujące relatywnie niewielkimi ilościami danych uczących, mają tendencję do dokładnego dopasowywania się do danych, to taki sposób deregulacji zmusza je do uczenia w sposób bardziej zgeneralizowany.\n",
        "\n",
        "W każdej turze uczenia się każdy z neuronów jest usuwany lub zostawiany w sieci. Szanse na usunięcie definiuje się poprzez określenie prawdopodobieństwa, z jakim neuron zostanie usunięty. W oryginalnej pracy było to 50% dla każdego neuronu. Obecnie możemy samodzielnie określić to prawdopodobieństwo, a do tego dla różnych warstw może być ono różne.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaOghdRclQaA"
      },
      "source": [
        "**Regularyzacja**\n",
        "Kolejną techniką do walki z przeuczeniem jest dokładanie do warstw kar, aby ich wartości były mniejsze. Te metody nazywamy regularyzacjami wag.\n",
        "\n",
        "Tutaj przykład dodania regularyzacji normą L2 do warstwy gęstej:\n",
        "```\n",
        "from tensorflow.keras import regularizers\n",
        " \n",
        "model2.add(Dense(10, activation = 'relu', \n",
        "                 kernel_regularizer=regularizers.l2(0.01)))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_yrF0SmlaMC"
      },
      "source": [
        "**EarlyStopping**\n",
        "W tensorflow mamy do dyspozycji funkcję EarlyStopping, która monitoruje stratę na zbiorze testowym po zakończeniu każdej epoki. Jeśli strata nie maleje, wówczas trening sieci zostaje zatrzymany. Należy zdefiniować 3 podstawowe parametry ustawiając early stopping:\n",
        "\n",
        "*   monitor – definiujemy, co chcemy \n",
        "monitorować na podstawie czego zatrzymamy proces uczenia,\n",
        "*   patience – tym parametrem definiujemy liczbę epok po ilu zatrzyma się nasz model jeśli nie zaobserwujemy zmniejszania się funkcji straty,\n",
        "*   verbose – a tutaj w jaki sposób będzie wyświetlana informacja o early stoping.\n",
        "\n",
        "```\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Flatten(input_shape=(28, 28)))\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(Dense(10, activation = 'softmax'))\n",
        " \n",
        "model2.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "EarlyStop = EarlyStopping(monitor='val_loss', \n",
        "                          patience=3,\n",
        "                          verbose=1)\n",
        " \n",
        "history2 = model2.fit(X_train, \n",
        "                    y_train, \n",
        "                    epochs=50,\n",
        "                    verbose=1,\n",
        "                    batch_size = 256,\n",
        "                    validation_data = (X_val, y_val),\n",
        "                    callbacks = [EarlyStop]\n",
        "                   )\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzUKTLh0z-El"
      },
      "source": [
        "# Materiały (do zapoznania się)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B44huBm7yszQ"
      },
      "source": [
        "Materiały do zapoznania się:\n",
        "\n",
        "* https://poloclub.github.io/cnn-explainer/\n",
        "- https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\n",
        "- https://www.freecodecamp.org/news/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050/\n",
        "- https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d\n",
        "- https://cv-tricks.com/cnn/understand-resnet-alexnet-vgg-inception/\n",
        "- https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5\n",
        "- http://yann.lecun.com/exdb/lenet/\n",
        "\n",
        "Best practices to build neural network models:\n",
        "\n",
        "* https://medium.com/@dipti.rohan.pawar/improving-performance-of-convolutional-neural-network-2ecfe0207de7\n",
        "\t\n",
        "* https://medium.com/towards-data-science/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-i-hyper-parameter-8129009f131b\n",
        "\t\n",
        "* https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-ii-hyper-parameter-42efca01e5d7\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Artykuły i snippety kodu + podstawowe zagadnienia do CNN\n",
        "\n",
        "* Idea konwolucji: http://sciagaprogramisty.blogspot.com/2018/01/konwolucja-wstep-do-neuronowych-sieci.html\n",
        "\n",
        "* NN architectures: https://pub.towardsai.net/main-types-of-neural-networks-and-its-applications-tutorial-734480d7ec8e?gi=28a8f0c56697 \n",
        "\t\n",
        "* https://www.kaggle.com/code/cdeotte/how-to-choose-cnn-architecture-mnist/notebook\n",
        "\t\n",
        "* https://medium.com/analytics-vidhya/a-guide-to-neural-network-layers-with-applications-in-keras-40ccb7ebb57a\n",
        "\t\n",
        "* https://towardsdatascience.com/a-quick-guide-to-neural-network-optimizers-with-applications-in-keras-e4635dd1cca4\n",
        "\t\n",
        "* https://medium.com/@andre_ye/a-quick-guide-to-neural-network-optimizers-with-applications-in-keras-e4635dd1cca4\n",
        "\t\n",
        "* https://towardsdatascience.com/a-guide-to-neural-network-loss-functions-with-applications-in-keras-3a3baa9f71c5\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Keras vs Tensorflow vs Pytorch\n",
        "\n",
        "\n",
        "\t\n",
        "* https://karliris62.medium.com/keras-vs-tensorflow-which-one-is-the-right-fit-for-your-project-7a166fe6c64b\n",
        "\t\n",
        "* https://www.edureka.co/blog/keras-vs-tensorflow-vs-pytorch/\n",
        "\t\n",
        "* https://towardsdatascience.com/batch-normalization-the-greatest-breakthrough-in-deep-learning-77e64909d81d\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Zadanie 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Po zapoznaniu się z obsluga interfejsu Google Colab. **Zaimplementuj** trzy wielowarstwowe Convolutional Neural Networks (CNNs) do klasyfikacji datasetów:\n",
        "* [MNIST](https://paperswithcode.com/dataset/mnist)\n",
        "* [Fashion MNIST](https://paperswithcode.com/dataset/fashion-mnist)\n",
        "* [CIFAR-10](https://paperswithcode.com/dataset/cifar-10)\n",
        "\n",
        "W tym celu wykorzystaj biblioteke **Keras** albo **PyTorch**.\n",
        "\n",
        "Ponizej przyklad jak wczytac dane w **Keras**\n",
        "\n",
        "```\n",
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 162s 343ms/step - loss: 0.2045 - accuracy: 0.9365\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 160s 341ms/step - loss: 0.0449 - accuracy: 0.9866\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 164s 349ms/step - loss: 0.0286 - accuracy: 0.9909\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 161s 344ms/step - loss: 0.0215 - accuracy: 0.9932\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 163s 347ms/step - loss: 0.0153 - accuracy: 0.9952\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 0.0372 - accuracy: 0.9891\n",
            "Test accuracy: 0.9890999794006348\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Wczytanie danych\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalizacja pikseli\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# Dodanie wymiaru kanału (1 dla MNIST)\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
        "\n",
        "# Definicja modelu\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Kompilacja modelu\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Trenowanie modelu\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "\n",
        "# Ocena modelu\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 70s 74ms/step - loss: 0.5570 - accuracy: 0.7940\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 63s 67ms/step - loss: 0.3373 - accuracy: 0.8766\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 66s 71ms/step - loss: 0.2842 - accuracy: 0.8974\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 65s 70ms/step - loss: 0.2517 - accuracy: 0.9074\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 63s 67ms/step - loss: 0.2304 - accuracy: 0.9144\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.2693 - accuracy: 0.9059\n",
            "Test accuracy: 0.9059000015258789\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Wczytanie danych\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalizacja pikseli\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# Dodanie wymiaru kanału\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
        "\n",
        "# Definicja modelu\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Kompilacja modelu\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Trenowanie modelu\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
        "\n",
        "# Ocena modelu\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "165/391 [===========>..................] - ETA: 1:52 - loss: 2.0068 - accuracy: 0.2714"
          ]
        }
      ],
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Wczytanie danych\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Normalizacja pikseli\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# Definicja modelu\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Kompilacja modelu\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Trenowanie modelu\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "\n",
        "# Ocena modelu\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
