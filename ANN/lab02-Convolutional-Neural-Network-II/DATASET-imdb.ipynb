{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET [IMDB](https://keras.io/api/datasets/imdb/)"
      ],
      "metadata": {
        "id": "IQkXkEpy09Qq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTbBVZHp8dGR",
        "outputId": "a23ed97b-7c74-4ae0-89d0-aa7a867d3c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "157/157 [==============================] - 32s 198ms/step - loss: 0.6235 - accuracy: 0.6715 - val_loss: 0.5155 - val_accuracy: 0.7596\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 30s 189ms/step - loss: 0.4416 - accuracy: 0.8004 - val_loss: 0.4053 - val_accuracy: 0.8238\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 30s 189ms/step - loss: 0.3442 - accuracy: 0.8527 - val_loss: 0.3539 - val_accuracy: 0.8454\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 31s 199ms/step - loss: 0.2811 - accuracy: 0.8855 - val_loss: 0.3275 - val_accuracy: 0.8592\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 30s 190ms/step - loss: 0.2322 - accuracy: 0.9103 - val_loss: 0.3174 - val_accuracy: 0.8638\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 30s 191ms/step - loss: 0.1921 - accuracy: 0.9307 - val_loss: 0.3128 - val_accuracy: 0.8706\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 31s 196ms/step - loss: 0.1550 - accuracy: 0.9478 - val_loss: 0.3170 - val_accuracy: 0.8670\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 32s 202ms/step - loss: 0.1227 - accuracy: 0.9618 - val_loss: 0.3202 - val_accuracy: 0.8750\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 31s 198ms/step - loss: 0.0957 - accuracy: 0.9737 - val_loss: 0.3415 - val_accuracy: 0.8660\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 30s 190ms/step - loss: 0.0714 - accuracy: 0.9837 - val_loss: 0.3501 - val_accuracy: 0.8710\n",
            "Tekst:\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    1   13 1247   14   20   18    6  378    7 2512   33    6    2\n",
            " 7975 6388   31  251   54   43  267  187    4 1108  610  184   52   11\n",
            " 3335   21    4   20    9  503 1992   13  657   36  586  353    8 3627\n",
            "  178   19    2 3380   23  503 1992  102   21   45    6 1141  155    8\n",
            "  168   46   18   10   10   54   13  296   12   13   16 3595  770   12\n",
            "  679   46    8   30  128   74   13  873   13   16  685   15   12   16\n",
            "    6  503 1992   21    4  302   26  184   52  434  128   74  135    2\n",
            "   39 4599   63   47 2136  302    5   12    9   87    8   67  308    2\n",
            "   11  142  334  972   39    2 1737   10   10  444   14   20  218   99\n",
            "   78   18    6  503 1242    5  434  290    4  107 2512   39    6 4688\n",
            "  213    7  650   12  218   61 1640  920  924   21   45   24   61  249\n",
            "  345   45 1604 2295]\n",
            "Etykieta:\n",
            "0\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Predykcja:\n",
            "[[0.63589025]]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Zdefiniujmy parametry modelu\n",
        "max_features = 10000 # liczba słów, które będą użyte w analizie tekstu\n",
        "maxlen = 200 # maksymalna liczba słów w każdej recenzji\n",
        "embedding_size = 128 # rozmiar wektora osadzenia słów (embedding)\n",
        "\n",
        "# Załadujmy zbiór danych IMDB\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Zmodyfikujmy dane tak, aby każda recenzja miała tę samą długość\n",
        "train_data = pad_sequences(train_data, maxlen=maxlen)\n",
        "test_data = pad_sequences(test_data, maxlen=maxlen)\n",
        "\n",
        "# Zdefiniujmy model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
        "model.add(Conv1D(32, 7, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Skompilujmy model\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Trenujmy model\n",
        "model.fit(train_data, train_labels, epochs=10, batch_size=128, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Przygotowanie słownika mapowania identyfikatorów słów na słowa\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# Dekodowanie losowo wybranej sekwencji tekstowej z testowego zestawu danych\n",
        "sample = np.random.randint(len(test_data))\n",
        "text = test_data[sample]\n",
        "label = test_labels[sample]\n",
        "\n",
        "# Wartości w zakresie 0-2 są zarezerwowane dla specjalnych znaków, zacznijmy od indeksu 3\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in text])\n",
        "print(f\"Tekst: {decoded_review}\")\n",
        "print(f\"Etykieta:{label}\")\n",
        "\n",
        "# Dokonanie predykcji na przykładowych danych\n",
        "prediction = model.predict(np.array([text]))\n",
        "print(f\"Predykcja: {prediction[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOu26yG5BamC",
        "outputId": "f75780ad-d4dd-4634-fdf1-2c5c648d85a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tekst: ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? i always liked this movie i have seen it so many times but i always enjoyed it the story is interesting and special but the only thing i have to disagree with is that i don't think max lived in a romanian monastery or what was that p they don't look that way in romania anyway back to the story played pretty well but as someone said before me his english needs to improve br br and there were some funny moments and some ? sad parts too it ? being seen i thought it was sweet that the giant wanted to find his love i recommended to you all it's not the best movie ever but it was nice\n",
            "Etykieta:1\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predykcja: [0.9997138]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nJNLf1WeB5Jc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}