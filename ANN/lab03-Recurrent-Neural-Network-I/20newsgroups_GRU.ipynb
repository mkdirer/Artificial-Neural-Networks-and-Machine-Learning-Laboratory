{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbRKpqPzRj0F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from tensorflow.keras.layers import Input, Embedding, GRU, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Wybor wszystkich kategorii\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')\n",
        "newsgroups_test = fetch_20newsgroups(subset='test')\n",
        "\n",
        "# Tokenizacja \n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(newsgroups_train.data)\n",
        "x_train = tokenizer.texts_to_sequences(newsgroups_train.data)\n",
        "x_test = tokenizer.texts_to_sequences(newsgroups_test.data)\n",
        "\n",
        "# Ustalenie tej samej dlugosci dla wszystkich danych\n",
        "max_length = max(len(sequence) for sequence in x_train)\n",
        "x_train = pad_sequences(x_train, maxlen=max_length)\n",
        "x_test = pad_sequences(x_test, maxlen=max_length)\n",
        "\n",
        "# One-hot encode kategorii\n",
        "y_train = to_categorical(newsgroups_train.target)\n",
        "y_test = to_categorical(newsgroups_test.target)\n",
        "\n",
        "# Budowanie modelu\n",
        "inputs = Input(shape=(max_length,))\n",
        "x = Embedding(input_dim=10000, output_dim=100, input_length=max_length)(inputs)\n",
        "x = GRU(units=64, activation='tanh')(x)\n",
        "x = Dense(units=32, activation='relu')(x)\n",
        "outputs = Dense(units=20, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "#Kompilacja i trenowanie\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))\n"
      ]
    }
  ]
}