{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":113059,"status":"ok","timestamp":1686644299499,"user":{"displayName":"Łukasz Wajda","userId":"17148359463873561665"},"user_tz":-120},"id":"0IN1BPvPxwf-","outputId":"6e7f368e-bb3c-4284-813d-adb4286b3306"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5, Batch 0/938, Loss=2.2976\n","Epoch 1/5, Batch 100/938, Loss=0.6739\n","Epoch 1/5, Batch 200/938, Loss=0.4583\n","Epoch 1/5, Batch 300/938, Loss=0.6484\n","Epoch 1/5, Batch 400/938, Loss=0.2436\n","Epoch 1/5, Batch 500/938, Loss=0.4165\n","Epoch 1/5, Batch 600/938, Loss=0.5523\n","Epoch 1/5, Batch 700/938, Loss=0.3055\n","Epoch 1/5, Batch 800/938, Loss=0.3611\n","Epoch 1/5, Batch 900/938, Loss=0.5763\n","Epoch 2/5, Batch 0/938, Loss=0.1721\n","Epoch 2/5, Batch 100/938, Loss=0.3941\n","Epoch 2/5, Batch 200/938, Loss=0.2749\n","Epoch 2/5, Batch 300/938, Loss=0.4482\n","Epoch 2/5, Batch 400/938, Loss=0.1216\n","Epoch 2/5, Batch 500/938, Loss=0.0440\n","Epoch 2/5, Batch 600/938, Loss=0.1325\n","Epoch 2/5, Batch 700/938, Loss=0.4232\n","Epoch 2/5, Batch 800/938, Loss=0.1052\n","Epoch 2/5, Batch 900/938, Loss=0.2356\n","Epoch 3/5, Batch 0/938, Loss=0.3211\n","Epoch 3/5, Batch 100/938, Loss=0.0611\n","Epoch 3/5, Batch 200/938, Loss=0.1706\n","Epoch 3/5, Batch 300/938, Loss=0.0506\n","Epoch 3/5, Batch 400/938, Loss=0.1453\n","Epoch 3/5, Batch 500/938, Loss=0.1298\n","Epoch 3/5, Batch 600/938, Loss=0.1189\n","Epoch 3/5, Batch 700/938, Loss=0.0784\n","Epoch 3/5, Batch 800/938, Loss=0.2079\n","Epoch 3/5, Batch 900/938, Loss=0.2640\n","Epoch 4/5, Batch 0/938, Loss=0.1259\n","Epoch 4/5, Batch 100/938, Loss=0.0667\n","Epoch 4/5, Batch 200/938, Loss=0.0846\n","Epoch 4/5, Batch 300/938, Loss=0.0768\n","Epoch 4/5, Batch 400/938, Loss=0.0896\n","Epoch 4/5, Batch 500/938, Loss=0.0554\n","Epoch 4/5, Batch 600/938, Loss=0.0608\n","Epoch 4/5, Batch 700/938, Loss=0.1288\n","Epoch 4/5, Batch 800/938, Loss=0.0604\n","Epoch 4/5, Batch 900/938, Loss=0.1343\n","Epoch 5/5, Batch 0/938, Loss=0.1581\n","Epoch 5/5, Batch 100/938, Loss=0.0817\n","Epoch 5/5, Batch 200/938, Loss=0.0981\n","Epoch 5/5, Batch 300/938, Loss=0.0616\n","Epoch 5/5, Batch 400/938, Loss=0.1546\n","Epoch 5/5, Batch 500/938, Loss=0.0625\n","Epoch 5/5, Batch 600/938, Loss=0.1493\n","Epoch 5/5, Batch 700/938, Loss=0.0480\n","Epoch 5/5, Batch 800/938, Loss=0.0541\n","Epoch 5/5, Batch 900/938, Loss=0.0443\n","Accuracy of the model on the 10000 test images: 96.7%\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","\n","# Przygotowanie danych\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n","\n","# Definicja modelu\n","class LogisticRegression(nn.Module):\n","    def __init__(self):\n","        super(LogisticRegression, self).__init__()\n","        self.linear1 = nn.Linear(784, 372)\n","        self.linear2 = nn.Linear(372, 128)\n","        self.linear3 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 784)\n","        x = F.relu(self.linear1(x))\n","        x = F.relu(self.linear2(x))\n","        x = self.linear3(x)\n","        return x\n","\n","model = LogisticRegression()\n","\n","# Definicja funkcji kosztu i optymalizatora\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.05)  # zmiana wskaźnika uczenia z 0.1 na 0.05\n","\n","# Trening modelu\n","num_epochs = 5\n","for epoch in range(num_epochs):\n","    for batch_idx, (data, targets) in enumerate(train_loader):\n","        # Ustawienie gradientu na 0\n","        optimizer.zero_grad()\n","        # Obliczenie predykcji modelu\n","        output = model(data)\n","        # Obliczenie wartości funkcji kosztu\n","        loss = criterion(output, targets)\n","        # Obliczenie gradientów\n","        loss.backward()\n","        # Aktualizacja wag modelu\n","        optimizer.step()\n","\n","        if batch_idx % 100 == 0:\n","            print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss={loss.item():.4f}')\n","\n","# Testowanie modelu\n","test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n","\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data, targets in test_loader:\n","        output = model(data)\n","        _, predicted = torch.max(output.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","print(f'Accuracy of the model on the {total} test images: {100 * correct / total}%')\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143552,"status":"ok","timestamp":1686646322610,"user":{"displayName":"Łukasz Wajda","userId":"17148359463873561665"},"user_tz":-120},"id":"OdAlmvbA2BUa","outputId":"5484ed73-31c1-4960-a933-d6b4e2e13545"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10, Batch 0/938, Loss=2.2870\n","Epoch 1/10, Batch 100/938, Loss=1.2283\n","Epoch 1/10, Batch 200/938, Loss=0.7304\n","Epoch 1/10, Batch 300/938, Loss=0.5785\n","Epoch 1/10, Batch 400/938, Loss=0.7587\n","Epoch 1/10, Batch 500/938, Loss=0.4955\n","Epoch 1/10, Batch 600/938, Loss=0.5311\n","Epoch 1/10, Batch 700/938, Loss=0.4591\n","Epoch 1/10, Batch 800/938, Loss=0.6001\n","Epoch 1/10, Batch 900/938, Loss=0.5859\n","Epoch 2/10, Batch 0/938, Loss=0.6372\n","Epoch 2/10, Batch 100/938, Loss=0.6805\n","Epoch 2/10, Batch 200/938, Loss=0.6114\n","Epoch 2/10, Batch 300/938, Loss=0.4404\n","Epoch 2/10, Batch 400/938, Loss=0.3534\n","Epoch 2/10, Batch 500/938, Loss=0.6206\n","Epoch 2/10, Batch 600/938, Loss=0.4333\n","Epoch 2/10, Batch 700/938, Loss=0.7182\n","Epoch 2/10, Batch 800/938, Loss=0.3081\n","Epoch 2/10, Batch 900/938, Loss=0.3817\n","Epoch 3/10, Batch 0/938, Loss=0.2953\n","Epoch 3/10, Batch 100/938, Loss=0.3708\n","Epoch 3/10, Batch 200/938, Loss=0.2982\n","Epoch 3/10, Batch 300/938, Loss=0.5550\n","Epoch 3/10, Batch 400/938, Loss=0.3776\n","Epoch 3/10, Batch 500/938, Loss=0.5357\n","Epoch 3/10, Batch 600/938, Loss=0.4224\n","Epoch 3/10, Batch 700/938, Loss=0.4156\n","Epoch 3/10, Batch 800/938, Loss=0.4210\n","Epoch 3/10, Batch 900/938, Loss=0.4614\n","Epoch 4/10, Batch 0/938, Loss=0.3649\n","Epoch 4/10, Batch 100/938, Loss=0.4229\n","Epoch 4/10, Batch 200/938, Loss=0.2638\n","Epoch 4/10, Batch 300/938, Loss=0.2602\n","Epoch 4/10, Batch 400/938, Loss=0.2798\n","Epoch 4/10, Batch 500/938, Loss=0.5298\n","Epoch 4/10, Batch 600/938, Loss=0.4601\n","Epoch 4/10, Batch 700/938, Loss=0.4405\n","Epoch 4/10, Batch 800/938, Loss=0.3670\n","Epoch 4/10, Batch 900/938, Loss=0.2444\n","Epoch 5/10, Batch 0/938, Loss=0.4227\n","Epoch 5/10, Batch 100/938, Loss=0.2528\n","Epoch 5/10, Batch 200/938, Loss=0.5076\n","Epoch 5/10, Batch 300/938, Loss=0.2121\n","Epoch 5/10, Batch 400/938, Loss=0.6142\n","Epoch 5/10, Batch 500/938, Loss=0.4068\n","Epoch 5/10, Batch 600/938, Loss=0.2747\n","Epoch 5/10, Batch 700/938, Loss=0.3074\n","Epoch 5/10, Batch 800/938, Loss=0.3856\n","Epoch 5/10, Batch 900/938, Loss=0.3690\n","Epoch 6/10, Batch 0/938, Loss=0.4768\n","Epoch 6/10, Batch 100/938, Loss=0.3220\n","Epoch 6/10, Batch 200/938, Loss=0.2792\n","Epoch 6/10, Batch 300/938, Loss=0.5756\n","Epoch 6/10, Batch 400/938, Loss=0.3122\n","Epoch 6/10, Batch 500/938, Loss=0.3147\n","Epoch 6/10, Batch 600/938, Loss=0.2673\n","Epoch 6/10, Batch 700/938, Loss=0.2743\n","Epoch 6/10, Batch 800/938, Loss=0.3525\n","Epoch 6/10, Batch 900/938, Loss=0.3178\n","Epoch 7/10, Batch 0/938, Loss=0.3957\n","Epoch 7/10, Batch 100/938, Loss=0.4069\n","Epoch 7/10, Batch 200/938, Loss=0.2743\n","Epoch 7/10, Batch 300/938, Loss=0.4049\n","Epoch 7/10, Batch 400/938, Loss=0.2807\n","Epoch 7/10, Batch 500/938, Loss=0.3625\n","Epoch 7/10, Batch 600/938, Loss=0.2258\n","Epoch 7/10, Batch 700/938, Loss=0.4154\n","Epoch 7/10, Batch 800/938, Loss=0.4294\n","Epoch 7/10, Batch 900/938, Loss=0.3801\n","Epoch 8/10, Batch 0/938, Loss=0.2673\n","Epoch 8/10, Batch 100/938, Loss=0.2634\n","Epoch 8/10, Batch 200/938, Loss=0.1728\n","Epoch 8/10, Batch 300/938, Loss=0.3073\n","Epoch 8/10, Batch 400/938, Loss=0.1720\n","Epoch 8/10, Batch 500/938, Loss=0.2573\n","Epoch 8/10, Batch 600/938, Loss=0.2304\n","Epoch 8/10, Batch 700/938, Loss=0.3674\n","Epoch 8/10, Batch 800/938, Loss=0.2748\n","Epoch 8/10, Batch 900/938, Loss=0.4045\n","Epoch 9/10, Batch 0/938, Loss=0.2559\n","Epoch 9/10, Batch 100/938, Loss=0.2598\n","Epoch 9/10, Batch 200/938, Loss=0.4312\n","Epoch 9/10, Batch 300/938, Loss=0.3287\n","Epoch 9/10, Batch 400/938, Loss=0.2632\n","Epoch 9/10, Batch 500/938, Loss=0.5527\n","Epoch 9/10, Batch 600/938, Loss=0.2878\n","Epoch 9/10, Batch 700/938, Loss=0.3458\n","Epoch 9/10, Batch 800/938, Loss=0.3063\n","Epoch 9/10, Batch 900/938, Loss=0.1718\n","Epoch 10/10, Batch 0/938, Loss=0.2363\n","Epoch 10/10, Batch 100/938, Loss=0.2489\n","Epoch 10/10, Batch 200/938, Loss=0.2844\n","Epoch 10/10, Batch 300/938, Loss=0.2477\n","Epoch 10/10, Batch 400/938, Loss=0.2160\n","Epoch 10/10, Batch 500/938, Loss=0.2423\n","Epoch 10/10, Batch 600/938, Loss=0.1586\n","Epoch 10/10, Batch 700/938, Loss=0.2344\n","Epoch 10/10, Batch 800/938, Loss=0.3272\n","Epoch 10/10, Batch 900/938, Loss=0.1790\n","Accuracy of the model on the 10000 test images: 9.3%\n"]}],"source":["import torch\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import matplotlib.pyplot as plt\n","\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","# Preparing data for training with DataLoaders\n","from torch.utils.data import DataLoader\n","\n","train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n","test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n","\n","# Definicja modelu\n","class LogisticRegression(nn.Module):\n","    def __init__(self):\n","        super(LogisticRegression, self).__init__()\n","        self.linear1 = nn.Linear(784, 372)\n","        self.linear2 = nn.Linear(372, 128)\n","        self.linear3 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 784)\n","        x = F.relu(self.linear1(x))\n","        x = F.relu(self.linear2(x))\n","        x = self.linear3(x)\n","        return x\n","\n","model = LogisticRegression()\n","\n","# Definicja funkcji kosztu i optymalizatora\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.05)  # zmiana wskaźnika uczenia z 0.1 na 0.05\n","\n","# Trening modelu\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    for batch_idx, (data, targets) in enumerate(train_dataloader):\n","        # Ustawienie gradientu na 0\n","        optimizer.zero_grad()\n","        # Obliczenie predykcji modelu\n","        output = model(data)\n","        # Obliczenie wartości funkcji kosztu\n","        loss = criterion(output, targets)\n","        # Obliczenie gradientów\n","        loss.backward()\n","        # Aktualizacja wag modelu\n","        optimizer.step()\n","\n","        if batch_idx % 100 == 0:\n","            print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss={loss.item():.4f}')\n","\n","# Testowanie modelu\n","test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n","\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data, targets in test_loader:\n","        output = model(data)\n","        _, predicted = torch.max(output.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","print(f'Accuracy of the model on the {total} test images: {100 * correct / total}%')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMEyy8INg7ZSIm/RGY97WKG","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
